## Probabilistic graphical model

### Problem 1
Q: Compare the graphical representation with feature vector-based and
kernel-based representations.

### Problem 2
Q: Explain why sometime a marginal distribution has to be completed
in graphical model.

### Problem 3
Q: Why a graphical model with latent variables can be a much harder problem?

### Problem 4
Q: What is the key assumption for graphical model? Using HMM as an exmaple,
hor much computational complexity has been reduced because of this assumption?

### Problem 5
Q: Why does EM not grarantee a global solution? What is a simple proof
for that?

### Problem 6
Q: Why is K-mean only an approxiamte and local solution for clustering?

### Problem 7
Q: How to interpret the HMM-based inference problem from a Bayesian
perspective, suing the forward/backward algorithm?

### Problem 8
Q: Show how to estimate a given hidden state for a given series of
observations using the alpha and beta factors.

### Problem 9
Q: For a Gaussian graphical model, what is the implication of sparsity
for sych a graphical model? How is such sparsity achieved computationally?

### Problem 10
Q: What would be the risk using a L1 as a relaxation for the sparsity
estimation?

